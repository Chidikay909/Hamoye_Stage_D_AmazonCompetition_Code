{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reading the train classes that contains the image names and tags from the directory\ntrain_classes = pd.read_csv('../input/planets-dataset/planet/planet/train_classes.csv')\ntrain_classes.head()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"  image_name                                       tags\n0    train_0                               haze primary\n1    train_1            agriculture clear primary water\n2    train_2                              clear primary\n3    train_3                              clear primary\n4    train_4  agriculture clear habitation primary road","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_0</td>\n      <td>haze primary</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_1</td>\n      <td>agriculture clear primary water</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_2</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_3</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_4</td>\n      <td>agriculture clear habitation primary road</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = set()\ndef splitting_tags(tags):\n    '''\n    Takes in tags column, splits the tags and store as a set\n    '''\n    [labels.add(tag) for tag in tags.split()]\n    \n# Create a copy of train_classes\ntrain_classes1 = train_classes.copy()\ntrain_classes1['tags'].apply(splitting_tags)\nlabels = list(labels)\nprint(labels)","execution_count":3,"outputs":[{"output_type":"stream","text":"['clear', 'blow_down', 'agriculture', 'road', 'slash_burn', 'cloudy', 'water', 'cultivation', 'selective_logging', 'artisinal_mine', 'partly_cloudy', 'conventional_mine', 'primary', 'blooming', 'haze', 'habitation', 'bare_ground']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#confirm that the length of the dataframe is the same as the shape\nassert len(train_classes1['image_name'].unique()) == train_classes1.shape[0]","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##One hot encoding is performed on the labels in train classes \n\nfor tag in labels:\n    train_classes1[tag] = train_classes1['tags'].apply(lambda x: 1 if tag in x.split() else 0)\n    \n## adding .jpg extension to the column image_name so as to have same name format as the image files\ntrain_classes1['image_name'] = train_classes1['image_name'].apply(lambda x: '{}.jpg'.format(x))\ntrain_classes1.head()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"    image_name                                       tags  clear  blow_down  \\\n0  train_0.jpg                               haze primary      0          0   \n1  train_1.jpg            agriculture clear primary water      1          0   \n2  train_2.jpg                              clear primary      1          0   \n3  train_3.jpg                              clear primary      1          0   \n4  train_4.jpg  agriculture clear habitation primary road      1          0   \n\n   agriculture  road  slash_burn  cloudy  water  cultivation  \\\n0            0     0           0       0      0            0   \n1            1     0           0       0      1            0   \n2            0     0           0       0      0            0   \n3            0     0           0       0      0            0   \n4            1     1           0       0      0            0   \n\n   selective_logging  artisinal_mine  partly_cloudy  conventional_mine  \\\n0                  0               0              0                  0   \n1                  0               0              0                  0   \n2                  0               0              0                  0   \n3                  0               0              0                  0   \n4                  0               0              0                  0   \n\n   primary  blooming  haze  habitation  bare_ground  \n0        1         0     1           0            0  \n1        1         0     0           0            0  \n2        1         0     0           0            0  \n3        1         0     0           0            0  \n4        1         0     0           1            0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n      <th>clear</th>\n      <th>blow_down</th>\n      <th>agriculture</th>\n      <th>road</th>\n      <th>slash_burn</th>\n      <th>cloudy</th>\n      <th>water</th>\n      <th>cultivation</th>\n      <th>selective_logging</th>\n      <th>artisinal_mine</th>\n      <th>partly_cloudy</th>\n      <th>conventional_mine</th>\n      <th>primary</th>\n      <th>blooming</th>\n      <th>haze</th>\n      <th>habitation</th>\n      <th>bare_ground</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_0.jpg</td>\n      <td>haze primary</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_1.jpg</td>\n      <td>agriculture clear primary water</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_2.jpg</td>\n      <td>clear primary</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_3.jpg</td>\n      <td>clear primary</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_4.jpg</td>\n      <td>agriculture clear habitation primary road</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing libraries for training\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, BatchNormalization, Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Dropout, Flatten\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining the columns,i.e the labels that were newly added to the train_classes via hot encoding.\ncolumns = list(train_classes1.columns[2:])","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"['clear',\n 'blow_down',\n 'agriculture',\n 'road',\n 'slash_burn',\n 'cloudy',\n 'water',\n 'cultivation',\n 'selective_logging',\n 'artisinal_mine',\n 'partly_cloudy',\n 'conventional_mine',\n 'primary',\n 'blooming',\n 'haze',\n 'habitation',\n 'bare_ground']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fbeta(y_true, y_pred, beta = 2, epsilon = 1e-4):\n    '''\n    Set y_true and y_pred\n\n    Args:\n        y_true: correct target values\n        Y_pred: predicted values returned by the classifer\n        beta = 2\n        epsilon= 1e-4\n        \n    Returns:\n        fbeta score\n    '''\n    \n    beta_squared = beta**2\n    \n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(tf.greater(tf.cast(y_pred, tf.float32), tf.constant(0.5)), tf.float32)\n    \n    tp = tf.reduce_sum(y_true * y_pred, axis = 1)\n    fp = tf.reduce_sum(y_pred, axis = 1) - tp\n    fn = tf.reduce_sum(y_true, axis = 1) - tp\n    \n    precision = tp/(tp+fp+epsilon)\n    recall = tp/(tp+fn+epsilon)\n    \n    fb = (1+beta_squared)*precision*recall / (beta_squared*precision+recall+epsilon)\n    return fb","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def multi_label_acc(y_true, y_pred, epsilon = 1e-4):\n    '''\n    Retuns accuracy value for multi_label classification\n    \n    Set y_true and y_pred\n\n    Args:\n        y_true: correct target values\n        Y_pred: predicted values returned by the classifer\n        epsilon= 1e-4\n        \n    Returns:\n        Accuracy score\n    '''\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(tf.greater(tf.cast(y_pred, tf.float32), tf.constant(0.5)), tf.float32)\n    \n    tp = tf.reduce_sum(y_true * y_pred, axis = 1)\n    fp = tf.reduce_sum(y_pred, axis = 1) - tp\n    fn = tf.reduce_sum(y_true, axis = 1) - tp\n    \n    y_true = tf.cast(y_true, tf.bool)\n    y_pred = tf.cast(y_pred, tf.bool)\n        \n    tn = tf.reduce_sum(tf.cast(tf.logical_not(y_true), tf.float32)\n                       * tf.cast(tf.logical_not(y_pred), tf.float32), axis = 1)\n    \n    return (tp+tn)/(tp+tn+fp+fn+epsilon)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#defining our model\ndef build_model():\n    model = Sequential()\n    model.add(BatchNormalization(input_shape=(128, 128, 3)))\n    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(17, activation='sigmoid'))\n\n    opt = Adam(lr=1e-4)\n    \n    # We need binary here, since categorical_crossentropy l1 norms the output before calculating loss.\n    model.compile(loss='binary_crossentropy',\n              optimizer=opt,\n              metrics=[multi_label_acc, fbeta])\n\n    return model","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#modelcheckpoint is set to monitor the model using validation fbeta score and save the best only\nsave_best_check_point = ModelCheckpoint(filepath = 'best_model.hdf5', \n                                        monitor = 'val_fbeta',\n                                        mode = 'max',\n                                        save_best_only = True,\n                                        save_weights_only = True)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#initializing imagedatagenerator with a validation split of 0.2\ntrain_image_gen = ImageDataGenerator(rescale = 1/255, validation_split = 0.2)\n\n#generating train data generator which is 80% of the train dataset\n#note that a generator contains both features and target of the data\ntrain_generator = train_image_gen.flow_from_dataframe(dataframe=train_classes1,\n                                                directory =\"../input/planets-dataset/planet/planet/train-jpg\",  \n                                                x_col=\"image_name\", y_col=columns, subset=\"training\", \n                                                batch_size=16,seed=2021, shuffle=True, \n                                                class_mode=\"raw\", target_size=(128,128))\n\n#generating validation data which is expected to be 20% of the train dataset since validation split is 0.2\nval_generator = train_image_gen.flow_from_dataframe(dataframe=train_classes1,\n                                                directory =\"../input/planets-dataset/planet/planet/train-jpg\",  \n                                                x_col=\"image_name\", y_col=columns, subset=\"validation\", \n                                                batch_size=16,seed=2021, shuffle=True, \n                                                class_mode=\"raw\", target_size=(128,128))","execution_count":13,"outputs":[{"output_type":"stream","text":"Found 32384 validated image filenames.\nFound 8095 validated image filenames.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#setting up step size for training and validation image data\nstep_train_size = int(np.ceil(train_generator.samples / train_generator.batch_size))\nstep_val_size = int(np.ceil(val_generator.samples / val_generator.batch_size))","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#initialize the model\nmodel1 = build_model()","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preview the model architecture\nmodel1.summary()","execution_count":16,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nbatch_normalization (BatchNo (None, 128, 128, 3)       12        \n_________________________________________________________________\nconv2d (Conv2D)              (None, 128, 128, 32)      896       \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 126, 126, 32)      9248      \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 63, 63, 32)        0         \n_________________________________________________________________\ndropout (Dropout)            (None, 63, 63, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 63, 63, 64)        18496     \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 61, 61, 64)        36928     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 30, 30, 64)        0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 30, 30, 64)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 30, 30, 128)       73856     \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 28, 28, 128)       147584    \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 14, 14, 128)       0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 14, 14, 128)       0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 14, 14, 256)       295168    \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 12, 12, 256)       590080    \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 6, 6, 256)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 9216)              0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               4719104   \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 17)                8721      \n=================================================================\nTotal params: 5,900,093\nTrainable params: 5,900,087\nNon-trainable params: 6\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fitting our model using the parameters already defined \nmodel1.fit(x = train_generator, \n           steps_per_epoch = step_train_size, \n           validation_data = val_generator, \n           validation_steps = step_val_size,epochs = 25, \n           callbacks = [save_best_check_point])","execution_count":17,"outputs":[{"output_type":"stream","text":"Epoch 1/25\n2024/2024 [==============================] - 175s 87ms/step - loss: 0.2170 - multi_label_acc: 0.9175 - fbeta: 0.7037 - val_loss: 0.1595 - val_multi_label_acc: 0.9374 - val_fbeta: 0.7822\nEpoch 2/25\n2024/2024 [==============================] - 116s 57ms/step - loss: 0.1622 - multi_label_acc: 0.9356 - fbeta: 0.7840 - val_loss: 0.1417 - val_multi_label_acc: 0.9440 - val_fbeta: 0.8070\nEpoch 3/25\n2024/2024 [==============================] - 116s 57ms/step - loss: 0.1479 - multi_label_acc: 0.9409 - fbeta: 0.8069 - val_loss: 0.1317 - val_multi_label_acc: 0.9468 - val_fbeta: 0.8189\nEpoch 4/25\n2024/2024 [==============================] - 117s 58ms/step - loss: 0.1383 - multi_label_acc: 0.9450 - fbeta: 0.8230 - val_loss: 0.1274 - val_multi_label_acc: 0.9498 - val_fbeta: 0.8407\nEpoch 5/25\n2024/2024 [==============================] - 115s 57ms/step - loss: 0.1329 - multi_label_acc: 0.9473 - fbeta: 0.8319 - val_loss: 0.1222 - val_multi_label_acc: 0.9510 - val_fbeta: 0.8460\nEpoch 6/25\n2024/2024 [==============================] - 115s 57ms/step - loss: 0.1271 - multi_label_acc: 0.9497 - fbeta: 0.8417 - val_loss: 0.1205 - val_multi_label_acc: 0.9527 - val_fbeta: 0.8484\nEpoch 7/25\n2024/2024 [==============================] - 114s 56ms/step - loss: 0.1222 - multi_label_acc: 0.9518 - fbeta: 0.8503 - val_loss: 0.1163 - val_multi_label_acc: 0.9546 - val_fbeta: 0.8627\nEpoch 8/25\n2024/2024 [==============================] - 115s 57ms/step - loss: 0.1184 - multi_label_acc: 0.9537 - fbeta: 0.8568 - val_loss: 0.1135 - val_multi_label_acc: 0.9552 - val_fbeta: 0.8625\nEpoch 9/25\n2024/2024 [==============================] - 114s 56ms/step - loss: 0.1151 - multi_label_acc: 0.9547 - fbeta: 0.8610 - val_loss: 0.1159 - val_multi_label_acc: 0.9540 - val_fbeta: 0.8574\nEpoch 10/25\n2024/2024 [==============================] - 115s 57ms/step - loss: 0.1107 - multi_label_acc: 0.9563 - fbeta: 0.8670 - val_loss: 0.1121 - val_multi_label_acc: 0.9579 - val_fbeta: 0.8662\nEpoch 11/25\n2024/2024 [==============================] - 115s 57ms/step - loss: 0.1082 - multi_label_acc: 0.9571 - fbeta: 0.8705 - val_loss: 0.1077 - val_multi_label_acc: 0.9582 - val_fbeta: 0.8743\nEpoch 12/25\n2024/2024 [==============================] - 115s 57ms/step - loss: 0.1048 - multi_label_acc: 0.9585 - fbeta: 0.8748 - val_loss: 0.1083 - val_multi_label_acc: 0.9576 - val_fbeta: 0.8729\nEpoch 13/25\n2024/2024 [==============================] - 114s 56ms/step - loss: 0.1016 - multi_label_acc: 0.9597 - fbeta: 0.8790 - val_loss: 0.1084 - val_multi_label_acc: 0.9582 - val_fbeta: 0.8663\nEpoch 14/25\n2024/2024 [==============================] - 114s 56ms/step - loss: 0.0995 - multi_label_acc: 0.9604 - fbeta: 0.8812 - val_loss: 0.1076 - val_multi_label_acc: 0.9591 - val_fbeta: 0.8807\nEpoch 15/25\n2024/2024 [==============================] - 114s 56ms/step - loss: 0.0965 - multi_label_acc: 0.9617 - fbeta: 0.8854 - val_loss: 0.1059 - val_multi_label_acc: 0.9596 - val_fbeta: 0.8809\nEpoch 16/25\n2024/2024 [==============================] - 114s 56ms/step - loss: 0.0931 - multi_label_acc: 0.9632 - fbeta: 0.8895 - val_loss: 0.1079 - val_multi_label_acc: 0.9589 - val_fbeta: 0.8786\nEpoch 17/25\n2024/2024 [==============================] - 114s 56ms/step - loss: 0.0902 - multi_label_acc: 0.9640 - fbeta: 0.8923 - val_loss: 0.1092 - val_multi_label_acc: 0.9587 - val_fbeta: 0.8732\nEpoch 18/25\n2024/2024 [==============================] - 113s 56ms/step - loss: 0.0875 - multi_label_acc: 0.9653 - fbeta: 0.8966 - val_loss: 0.1108 - val_multi_label_acc: 0.9596 - val_fbeta: 0.8816\nEpoch 19/25\n2024/2024 [==============================] - 114s 56ms/step - loss: 0.0837 - multi_label_acc: 0.9665 - fbeta: 0.9011 - val_loss: 0.1141 - val_multi_label_acc: 0.9595 - val_fbeta: 0.8818\nEpoch 20/25\n2024/2024 [==============================] - 115s 57ms/step - loss: 0.0814 - multi_label_acc: 0.9677 - fbeta: 0.9036 - val_loss: 0.1155 - val_multi_label_acc: 0.9595 - val_fbeta: 0.8773\nEpoch 21/25\n2024/2024 [==============================] - 113s 56ms/step - loss: 0.0779 - multi_label_acc: 0.9690 - fbeta: 0.9082 - val_loss: 0.1141 - val_multi_label_acc: 0.9601 - val_fbeta: 0.8858\nEpoch 22/25\n2024/2024 [==============================] - 113s 56ms/step - loss: 0.0754 - multi_label_acc: 0.9698 - fbeta: 0.9107 - val_loss: 0.1175 - val_multi_label_acc: 0.9600 - val_fbeta: 0.8834\nEpoch 23/25\n2024/2024 [==============================] - 114s 56ms/step - loss: 0.0723 - multi_label_acc: 0.9713 - fbeta: 0.9141 - val_loss: 0.1240 - val_multi_label_acc: 0.9591 - val_fbeta: 0.8815\nEpoch 24/25\n2024/2024 [==============================] - 113s 56ms/step - loss: 0.0691 - multi_label_acc: 0.9724 - fbeta: 0.9171 - val_loss: 0.1199 - val_multi_label_acc: 0.9590 - val_fbeta: 0.8812\nEpoch 25/25\n2024/2024 [==============================] - 114s 56ms/step - loss: 0.0661 - multi_label_acc: 0.9736 - fbeta: 0.9220 - val_loss: 0.1244 - val_multi_label_acc: 0.9591 - val_fbeta: 0.8831\n","name":"stdout"},{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7fef18099250>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#initializing a second model to make predictions\nmodel2 = build_model()","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##adding .jpg extension to image name in the sample submission file\nsample_submission = pd.read_csv('../input/planets-dataset/planet/planet/sample_submission.csv')\nsample_submission1 = sample_submission.copy()\nsample_submission1['image_name'] = sample_submission1['image_name'].apply(lambda x: '{}.jpg'.format(x))\nsample_submission1.head()","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"   image_name                                  tags\n0  test_0.jpg  primary clear agriculture road water\n1  test_1.jpg  primary clear agriculture road water\n2  test_2.jpg  primary clear agriculture road water\n3  test_3.jpg  primary clear agriculture road water\n4  test_4.jpg  primary clear agriculture road water","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_0.jpg</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_1.jpg</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_2.jpg</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_3.jpg</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_4.jpg</td>\n      <td>primary clear agriculture road water</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#loading in the weights of the trained model\nmodel2.load_weights('best_model.hdf5')","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Divide the sample submission file into two splits,\n# first test1_df which contains the first 40669 images \ntest1_df = sample_submission1.iloc[:40669]['image_name'].reset_index().drop('index', axis =1)\ntest1_df.head()","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"   image_name\n0  test_0.jpg\n1  test_1.jpg\n2  test_2.jpg\n3  test_3.jpg\n4  test_4.jpg","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_0.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_1.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_2.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_3.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_4.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#initialize imagedatagenerator for the test images and also rescaling\ntest_image_gen = ImageDataGenerator(rescale = 1/255)\n\n\n#creating a generator for the images found in the first test image files\ntest_generator1 = test_image_gen.flow_from_dataframe(dataframe=test1_df, \n                                                directory=\"../input/planets-dataset/planet/planet/test-jpg\", \n                                                x_col=\"image_name\", \n                                                y_col=None, \n                                                batch_size=16, \n                                                shuffle=False, \n                                                class_mode=None, \n                                                target_size=(128,128))\n\nstep_test_size1 = int(np.ceil(test_generator1.samples/test_generator1.batch_size))","execution_count":22,"outputs":[{"output_type":"stream","text":"Found 40669 validated image filenames.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#first, we reset the test generator to avoid shuffling of index as we want it to be orderly\ntest_generator1.reset()\npred1 = model2.predict(test_generator1, steps = step_test_size1, verbose = 1)","execution_count":23,"outputs":[{"output_type":"stream","text":"2542/2542 [==============================] - 153s 60ms/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#this is to get the filenames in the generator using the attribute .filenames\nfile_names1 = test_generator1.filenames\n\n#convert the predicted values to a dataframe and join two labels together if the probability of occurrance \n#of the label is greater than 0.5 \npred_tags1 = pd.DataFrame(pred1)\npred_tags1 = pred_tags1.apply(lambda x: ' '.join(np.array(labels)[x>0.5]), axis = 1)\n\n#then the result should look like this \nresult1 = pd.DataFrame({'image_name': file_names1, 'tags': pred_tags1})\nresult1.head()","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"   image_name                       tags\n0  test_0.jpg              clear primary\n1  test_1.jpg              clear primary\n2  test_2.jpg      partly_cloudy primary\n3  test_3.jpg  clear agriculture primary\n4  test_4.jpg      partly_cloudy primary","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_0.jpg</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_1.jpg</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_2.jpg</td>\n      <td>partly_cloudy primary</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_3.jpg</td>\n      <td>clear agriculture primary</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_4.jpg</td>\n      <td>partly_cloudy primary</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#second batch of the test dataset\ntest2_df = sample_submission1.iloc[40669:]['image_name'].reset_index().drop('index', axis =1)\ntest2_df.head()","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"      image_name\n0     file_0.jpg\n1     file_1.jpg\n2    file_10.jpg\n3   file_100.jpg\n4  file_1000.jpg","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>file_0.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>file_1.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>file_10.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>file_100.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>file_1000.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating a generator for the second batch of test image files\ntest_generator2 = test_image_gen.flow_from_dataframe(dataframe=test2_df, \n                                                directory=\"../input/planets-dataset/test-jpg-additional/test-jpg-additional\", \n                                                x_col=\"image_name\", \n                                                y_col=None, \n                                                batch_size=16, \n                                                shuffle=False, \n                                                class_mode=None, \n                                                target_size=(128,128))\n\nstep_test_size2 = int(np.ceil(test_generator2.samples/test_generator2.batch_size))","execution_count":26,"outputs":[{"output_type":"stream","text":"Found 20522 validated image filenames.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we reset the generator to avoid shuffling, then make prediction on the generator\ntest_generator2.reset()\npred2 = model2.predict(test_generator2, steps = step_test_size2, verbose = 1)","execution_count":27,"outputs":[{"output_type":"stream","text":"1283/1283 [==============================] - 76s 59ms/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#this is to get the filenames in the generator using the attribute .filenames\nfile_names2 = test_generator2.filenames\n\n#convert the predicted values to a dataframe and join two labels together if the probability of occurrance \n#of the label is greater than 0.5\npred_tags2 = pd.DataFrame(pred2)\npred_tags2 = pred_tags2.apply(lambda x: ''.join(np.array(labels)[x>0.5]), axis = 1)\n\n#then the result should look like this\nresult2 = pd.DataFrame({'image_name': file_names2, 'tags': pred_tags2})\nresult2.head()","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"      image_name                             tags\n0     file_0.jpg                     clearprimary\n1     file_1.jpg  agriculturepartly_cloudyprimary\n2    file_10.jpg           agricultureroadprimary\n3   file_100.jpg                clearwaterprimary\n4  file_1000.jpg                     clearprimary","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>file_0.jpg</td>\n      <td>clearprimary</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>file_1.jpg</td>\n      <td>agriculturepartly_cloudyprimary</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>file_10.jpg</td>\n      <td>agricultureroadprimary</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>file_100.jpg</td>\n      <td>clearwaterprimary</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>file_1000.jpg</td>\n      <td>clearprimary</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for the final result of the predicted tags for the test images,\n# we need to concat the first and second results in \n#that order to avoid shuffling the index\nlast_result = pd.concat([result1, result2])\n\nlast_result = last_result.reset_index().drop('index', axis =1)\n\nprint(last_result.shape)\n#print the final result\nlast_result.head()","execution_count":29,"outputs":[{"output_type":"stream","text":"(61191, 2)\n","name":"stdout"},{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"   image_name                       tags\n0  test_0.jpg              clear primary\n1  test_1.jpg              clear primary\n2  test_2.jpg      partly_cloudy primary\n3  test_3.jpg  clear agriculture primary\n4  test_4.jpg      partly_cloudy primary","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_0.jpg</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_1.jpg</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_2.jpg</td>\n      <td>partly_cloudy primary</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_3.jpg</td>\n      <td>clear agriculture primary</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_4.jpg</td>\n      <td>partly_cloudy primary</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we need to remove the .jpg extension from the image_name of the\n# last_result because from the sample submission the \n#extension was not there, we added it for easy manipulation of the data.\nlast_result['image_name'] = last_result['image_name'].apply(lambda x: x[:-4])\nlast_result.head()","execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"  image_name                       tags\n0     test_0              clear primary\n1     test_1              clear primary\n2     test_2      partly_cloudy primary\n3     test_3  clear agriculture primary\n4     test_4      partly_cloudy primary","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_0</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_1</td>\n      <td>clear primary</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_2</td>\n      <td>partly_cloudy primary</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_3</td>\n      <td>clear agriculture primary</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_4</td>\n      <td>partly_cloudy primary</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finally, we save the result to a csv file using the .to_csv() \n# method and setting the index to false.\nlast_result.to_csv('submission13.csv', index = False)","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}